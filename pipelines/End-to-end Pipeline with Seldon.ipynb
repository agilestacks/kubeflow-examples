{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Pipelines: from Training to Serving\n",
    "\n",
    "## Introduction\n",
    "With [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/) you can build entire workflows that automate the steps involved in going from training a machine learning model to actually serving an optimized version of it.\n",
    "These steps can be triggered automatically by a CI/CD workflow or on demand from a command line or notebook.\n",
    "\n",
    "Kubeflow Pipelines (`kfp`) comes with a user interface for managing and tracking experiments, jobs, and runs.\n",
    "A pipeline is a description of a machine learning workflow, replete with all inputs and outputs.\n",
    "In Kubeflow Pipelines, an **experiment** is a [workspace](../metadata/Metadata%20SDK.ipynb) where you can _experiment with_ different configuration of your pipelines.\n",
    "Experiments are a way to organize runs of jobs into logical groups.\n",
    "A **run** is simply a single execution (instance) of a pipeline.\n",
    "Kubeflow Pipelines also supports recurring runs, which is a repeatable run of a pipeline.\n",
    "Based on a so-called **run trigger** an instance of a pipeline with its run configuration is periodically started.\n",
    "As of now, [run triggers](https://www.kubeflow.org/docs/pipelines/overview/concepts/run-trigger/) are time-based (i.e. not event-based).\n",
    "\n",
    "In the UI, there is a pictorial representation of the runtime execution of a pipeline.\n",
    "This **graph** consists of one or more steps (i.e. nodes).\n",
    "Each step\n",
    "The directed edges (arrows) show the parent/child relationship: A &rarr; B means that B depends on A; B cannot start until A has successfully completed.\n",
    "\n",
    "A **component** performs a single step in the pipeline (e.g. data ingestion, data preprocessing, data transformation, model training, hyperparameter tuning).\n",
    "It is analogous to a function: it has a name, (metadata) parameters and return values (interface), and a body (implementation).\n",
    "It must therefore be self-contained.\n",
    "Each component must be packaged as a Docker image.\n",
    "Please note that components are independently executed: they do not share the same process and cannot share in-memory data.\n",
    "\n",
    "### What You'll Learn\n",
    "This notebook trains a simple (MNIST) model in TensorFlow and serves it with [Seldon](https://www.kubeflow.org/docs/components/serving/seldon/), converts your ML models (Tensorflow, Pytorch, H2o, etc.) or language wrappers (Python, Java, etc.) into production REST/GRPC microservices.\n",
    "What this means is that you do not have to worry about which machines it runs on, networking, autoscaling, health checks, and what have you.\n",
    "Instead, you can focus on what matters to you: the model and a REST API you can call for predictions.\n",
    "If you are familiar with Kubernetes, you can even do [out-of-the-box canary deployments](https://github.com/kubeflow/kfserving/tree/master/docs/samples/tensorflow), in which a percentage of traffic is directed to the 'canary (in the coal mine)' with the latest model to ensure it functions properly before completely rolling out any (potentially problematic) updates.\n",
    "\n",
    "If you prefer to use a more sophisticated model or a PyTorch-based one, you can check out the relevant notebooks: [MNIST with TensorFlow](../training/tensorflow/MNIST%20with%20TensorFlow.ipynb) or [MNIST with PyTorch](../training/pytorch/MNIST%20with%20PyTorch.ipynb).\n",
    "\n",
    "KFServing reads the model file from [MinIO](https://min.io/), an open-source S3-compliant object storage tool, which is already included with your Kubeflow installation.\n",
    "\n",
    "We also use MinIO to provide the input data set to the pipeline. This way it can run without a connection to the Internet.\n",
    "\n",
    "### What You'll Need\n",
    "This notebook.\n",
    "\n",
    "## Prerequisites\n",
    "Let's make sure Kubeflow Pipelines is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting kfp==1.0.1\n",
      "  Using cached kfp-1.0.1.tar.gz (116 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp==1.0.1) (5.3)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp==1.0.1) (1.25.0)\n",
      "Requirement already satisfied: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp==1.0.1) (10.0.1)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (1.26.1)\n",
      "Requirement already satisfied: requests_toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (0.9.1)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp==1.0.1) (1.2.2)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=0.2.5 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (1.3.0)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp==1.0.1) (3.2.0)\n",
      "Requirement already satisfied: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (0.8.7)\n",
      "Requirement already satisfied: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (7.1.2)\n",
      "Requirement already satisfied: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (1.2.11)\n",
      "Requirement already satisfied: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp==1.0.1) (0.1.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp==1.0.1) (4.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp==1.0.1) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp==1.0.1) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp==1.0.1) (44.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp==1.0.1) (1.13.0)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp==1.0.1) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp==1.0.1) (1.3.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in /home/jovyan/.local/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (1.26.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (2019.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/jovyan/.local/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (3.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (1.51.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/jovyan/.local/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (20.9)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (2.22.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp==1.0.1) (0.15.7)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp==1.0.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp==1.0.1) (19.3.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.1) (2.8.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3>=1.15 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp-server-api<2.0.0,>=0.2.5->kfp==1.0.1) (1.24.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.0.1) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp==1.0.1) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (2.4.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==1.0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==1.0.1) (2.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp==1.0.1) (1.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema>=3.0.1->kfp==1.0.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata->jsonschema>=3.0.1->kfp==1.0.1) (8.0.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp==1.0.1) (3.1.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp==1.0.1) (0.30.0)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.0.1-py3-none-any.whl size=160933 sha256=e73a845410421d0728cb7f93ec5bd5bb1e6328d344e6c91ce46bc5a9f378ca22\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/fd/88/f8/c59eb844a712adafc79d427cb057b1994c6b3d227893c554a8\n",
      "Successfully built kfp\n",
      "Installing collected packages: kfp\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 1.4.0\n",
      "    Uninstalling kfp-1.4.0:\n",
      "      Successfully uninstalled kfp-1.4.0\n",
      "Successfully installed kfp-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install kfp==1.0.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/13/0d298ac709aecdc2e52806de70071ad71c5d3f16bbeaeafab3a0987b28c3/kfp-1.4.0.tar.gz (159kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 36.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=5.3 in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: requests_toolbelt>=0.8.0 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<2.0.0,>=1.1.2 in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (1.2.11)\n",
      "Requirement already satisfied, skipping upgrade: strip-hints in /home/jovyan/.local/lib/python3.6/site-packages (from kfp) (0.1.9)\n",
      "Collecting docstring-parser>=0.7.3\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/b0/4d4601b2a25de597cbb84937be42cd238217bebaacde0d75707e6c89b641/docstring_parser-0.7.3.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2.0,>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/c2/6c1bdad961537c8078c66d57e4562455bffe06ce510d4c98d37283a28c43/kfp_pipeline_spec-0.1.5-py3-none-any.whl\n",
      "Collecting fire>=0.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/07/a119a1aa04d37bc819940d95ed7e135a7dcca1c098123a3764a6dcace9e7/fire-0.4.0.tar.gz (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 17.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /home/jovyan/.local/lib/python3.6/site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /home/jovyan/.local/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.26.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /home/jovyan/.local/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /home/jovyan/.local/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (8.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2.4.6)\n",
      "Building wheels for collected packages: docstring-parser\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.7.3-cp36-none-any.whl size=19230 sha256=745abe7693db35b17dc014a60dee311c5852784932f4e4606be6fd59161e4c85\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/87/6b/a2/be5c15ac743037f1b006ae4f92a6a81e79a74084cd3ff6fc4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully built docstring-parser\n",
      "Building wheels for collected packages: kfp, fire\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.4.0-cp36-none-any.whl size=222156 sha256=5361349d5cb81d9cfc8335de4debe1fb8cba3d9133357777783b840f1ba7299e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/6d/7d/29/3dddd13038f8423fd4fdee8bf12a6e547f4c7cde5ff1be1b2d\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=117174 sha256=80dfa2fa4688c65c881896c604c04e433508e6a8af09e3f55bf1068dd8ad2648\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/af/19/30/1ea0cad502dcb4e66ed5a690279628c827aea38bbbab75d5ed\n",
      "Successfully built kfp fire\n",
      "Installing collected packages: docstring-parser, kfp-pipeline-spec, fire, kfp\n",
      "  Found existing installation: kfp 1.0.1\n",
      "    Uninstalling kfp-1.0.1:\n",
      "      Successfully uninstalled kfp-1.0.1\n",
      "Successfully installed docstring-parser-0.7.3 fire-0.4.0 kfp-1.4.0 kfp-pipeline-spec-0.1.5\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! pip install --user -U kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Name: kfp\n",
      "Version: 1.0.1\n",
      "Summary: KubeFlow Pipelines SDK\n",
      "Home-page: UNKNOWN\n",
      "Author: google\n",
      "Author-email: None\n",
      "License: UNKNOWN\n",
      "Location: /home/jovyan/.local/lib/python3.6/site-packages\n",
      "Requires: kubernetes, jsonschema, requests-toolbelt, google-auth, click, tabulate, strip-hints, google-cloud-storage, PyYAML, kfp-server-api, cloudpickle, Deprecated\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Configure Credentials\n",
    "In order for Seldon to access MinIO, the credentials must be added to the default service account.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Seldon is imported as a pipeline component (<code>ContainerOp</code>) in this notebook.\n",
    "    Consequently, it does not allow configuration of custom service accounts.  Encode credentials to base24: <code>echo -n admin:Admin123 | base64</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from importlib import reload\n",
    "import boto3\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210216 01:42:59 <ipython-input-50-7681aa5604a8>:25] Running in namespace igor\n",
      "[I 210216 01:42:59 <ipython-input-50-7681aa5604a8>:26] Using docker registry stimulating-ladymaya-962-harbor.app.stimulating-ladymaya-962.bubble.superhub.io/library\n",
      "[I 210216 01:42:59 <ipython-input-50-7681aa5604a8>:27] Using minio instance with endpoint 'minio.kubeflow-data.svc.cluster.local:9000'\n"
     ]
    }
   ],
   "source": [
    "from kubernetes import client as k8s_client\n",
    "from kubernetes.client import rest as k8s_rest\n",
    "from kubeflow import fairing   \n",
    "from kubeflow.fairing import utils as fairing_utils\n",
    "from kubeflow.fairing.builders import append\n",
    "from kubeflow.fairing.deployers import job\n",
    "from kubeflow.fairing.preprocessors import base as base_preprocessor\n",
    "\n",
    "DOCKER_REGISTRY = environ['HARBOR_HOST'] + \"/library\"\n",
    "namespace = fairing_utils.get_current_k8s_namespace()\n",
    "\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes.client.rest import ApiException\n",
    "\n",
    "api_client = k8s_client.CoreV1Api()\n",
    "\n",
    "\n",
    "s3_endpoint = environ['AWS_S3_ENDPOINT']\n",
    "minio_service_endpoint = s3_endpoint\n",
    "minio_endpoint = \"http://\"+s3_endpoint\n",
    "minio_username = environ['AWS_ACCESS_KEY_ID']\n",
    "minio_key = environ['AWS_SECRET_ACCESS_KEY']\n",
    "minio_region = \"us-east-1\"\n",
    "\n",
    "logging.info(f\"Running in namespace {namespace}\")\n",
    "logging.info(f\"Using docker registry {DOCKER_REGISTRY}\")\n",
    "logging.info(f\"Using minio instance with endpoint '{s3_endpoint}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint = environ['AWS_S3_ENDPOINT']\n",
    "minio_service_endpoint = s3_endpoint\n",
    "minio_endpoint = \"http://\"+s3_endpoint\n",
    "minio_username = environ['AWS_ACCESS_KEY_ID']\n",
    "minio_key = environ['AWS_SECRET_ACCESS_KEY']\n",
    "minio_region = \"us-east-1\"\n",
    "MINIO_URL=minio_endpoint\n",
    "KUBEFLOW_URL=environ['KUBEFLOW_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate minio_secret.yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-s3-secret\n",
    "  annotations:\n",
    "     serving.kubeflow.org/s3-endpoint: {minio_endpoint}\n",
    "     serving.kubeflow.org/s3-usehttps: \"0\" # Default: 1. Must be 0 when testing with MinIO!\n",
    "type: Opaque\n",
    "data:\n",
    "  awsAccessKeyID: {minio_username}\n",
    "  awsSecretAccessKey: {minio_key}\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: default\n",
    "secrets:\n",
    "  - name: minio-s3-secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-s3-secret unchanged\n",
      "serviceaccount/default configured\n"
     ]
    }
   ],
   "source": [
    "! kubectl apply -f minio_secret.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy input data set into MinIO using its CLI\n",
    "\n",
    "First, we configure credentials for `mc`, the MinIO command line client.\n",
    "We then use it to create a bucket, upload the dataset to it, and set access policy so that the pipeline can download it from MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket\n",
      "kubeflow-us-east-1\n",
      "stimulat-mnist\n",
      "tutorial\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from importlib import reload\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "s3 = boto3.client('s3', endpoint_url=\"http://\"+environ['AWS_S3_ENDPOINT'], \n",
    "             aws_access_key_id=environ['AWS_ACCESS_KEY_ID'],\n",
    "             aws_secret_access_key=environ['AWS_SECRET_ACCESS_KEY'],\n",
    "             region_name='us-east-1')\n",
    "for _ in s3.list_buckets()[\"Buckets\"]:\n",
    "  print(_[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   s3.delete_object(Bucket='tutorial', Key='datasets.tar.gz') \n",
    "   s3.delete_bucket(Bucket='tutorial')\n",
    "except s3.exceptions.from_code('NoSuchBucket'):\n",
    "    print('No such bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   s3.create_bucket(Bucket='tutorial', ACL='public-read-write')\n",
    "except s3.exceptions.from_code('BucketAlreadyOwnedByYou'):\n",
    "    print('Bucket already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(Filename= r'datasets.tar.gz',\n",
    "               Bucket='tutorial',\n",
    "               Key= 'datasets.tar.gz',\n",
    "               ExtraArgs={'ACL': 'public-read-write'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Key': 'datasets.tar.gz',\n",
       "  'LastModified': datetime.datetime(2021, 2, 15, 23, 36, 42, 163000, tzinfo=tzlocal()),\n",
       "  'ETag': '\"b09555beaf4e5cc06d181d24fa9eb2e3-4\"',\n",
       "  'Size': 28440545,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'Owner': {'DisplayName': '',\n",
       "   'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_objects(Bucket='tutorial',MaxKeys=2,Prefix='datasets.tar.gz')['Contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Implement Kubeflow Pipelines Components\n",
    "As we said before, components are self-contained pieces of code: Python functions.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    The function must be completely self-contained.\n",
    "    No code (incl. imports) can be defined outside of the body itself.\n",
    "    All imports <a href=\"https://www.kubeflow.org/docs/pipelines/sdk/lightweight-python-components/\">must be included</a> in the function body itself!\n",
    "    Imported packages must be available in the base image.<br><br>\n",
    "    Why? Because each component will be packaged as a Docker image.\n",
    "    The base image must therefore contain all dependencies.\n",
    "    Any dependencies you install manually in the notebook are invisible to the Python function once it's inside the image.\n",
    "    The function itself becomes the entrypoint of the image, which is why all auxiliary functions must be defined inside the function.\n",
    "    That does cause some unfortunate duplication, but it also means you do not have to worry about the mechanism of packaging, as we shall see below.\n",
    "</div>\n",
    "\n",
    "For our pipeline, we shall define four components:\n",
    "- Download the MNIST data set\n",
    "- Train the TensorFlow model\n",
    "- Evaluate the trained model\n",
    "- Export the trained model\n",
    "- Serve the trained model\n",
    "\n",
    "We also need the current Kubernetes namespace, which we can dynamically grab using [Kubeflow Fairing](../fairing/Kubeflow%20Fairing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 210216 01:52:16 <ipython-input-66-4e418488b386>:18] Running in namespace igor\n",
      "[I 210216 01:52:16 <ipython-input-66-4e418488b386>:19] Using minio instance with endpoint 'http://minio.kubeflow-data.svc.cluster.local:9000'\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "import logging\n",
    "import kfp.components as components\n",
    "import kfp.dsl as dsl\n",
    "\n",
    "from kfp.components import InputPath, OutputPath\n",
    "\n",
    "namespace = environ['THIS_NAMESPACE']\n",
    "s3_endpoint = environ['AWS_S3_ENDPOINT']\n",
    "minio_service_endpoint = s3_endpoint\n",
    "minio_endpoint = \"http://\"+s3_endpoint\n",
    "minio_username = environ['AWS_ACCESS_KEY_ID']\n",
    "minio_key = environ['AWS_SECRET_ACCESS_KEY']\n",
    "minio_region = \"us-east-1\"\n",
    "\n",
    "logging.info(f\"Running in namespace {namespace}\")\n",
    "logging.info(f\"Using minio instance with endpoint '{minio_endpoint}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function arguments specified with `InputPath` and `OutputPath` are the key to defining dependencies.\n",
    "For now, it suffices to think of them as the input and output of each step.\n",
    "How we can define dependencies is explained in the [next section](#How-to-Combine-the-Components-into-a-Pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 1: Download the MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(data_dir: OutputPath(str)):\n",
    "    \"\"\"Download the MNIST data set to the KFP volume to share it among all steps\"\"\"\n",
    "    import urllib.request\n",
    "    import tarfile\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    url = \"http://buckets.app.small-julie-379.bubble.superhub.io/tutorial/datasets.tar.gz\"\n",
    "    #url = \"http://minio.kubeflow-data.svc.cluster.local:9000/tutorial/datasets.tar.gz\"\n",
    "    stream = urllib.request.urlopen(url)\n",
    "    tar = tarfile.open(fileobj=stream, mode=\"r|gz\")\n",
    "    tar.extractall(path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 2: Train the Model\n",
    "For both the training and evaluation we must divide the integer-valued pixel values by 255 to scale all values into the [0, 1] (floating-point) range.\n",
    "This function must be copied into both component functions (cf. `normalize_image`).\n",
    "\n",
    "If you wish to learn more about the model code, please have a look at the [MNIST with TensorFlow](../training/MNIST%20with%20TensorFlow.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_dir: InputPath(str), model_dir: OutputPath(str)):\n",
    "    \"\"\"Trains a single-layer CNN for 5 epochs using a pre-downloaded dataset.\n",
    "    Once trained, the model is persisted to `model_dir`.\"\"\"\n",
    "\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    def normalize_image(image, label):\n",
    "        \"\"\"Normalizes images: `uint8` -> `float32`\"\"\"\n",
    "        return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    ds_train, ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=\"train\",\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "        download=False,\n",
    "        data_dir=f\"{data_dir}/datasets\",\n",
    "    )\n",
    "\n",
    "    # See: https://www.tensorflow.org/datasets/keras_example#build_training_pipeline\n",
    "    ds_train = ds_train.map(\n",
    "        normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "    ds_train = ds_train.batch(128)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=5,\n",
    "    )\n",
    "\n",
    "    model.save(model_dir)\n",
    "    print(f\"Model saved {model_dir}\")\n",
    "    print(os.listdir(model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 3: Evaluate the Model\n",
    "With the following Python function the model is evaluated.\n",
    "The metrics [metadata](https://www.kubeflow.org/docs/pipelines/sdk/pipelines-metrics/) (loss and accuracy) is available to the Kubeflow Pipelines UI.\n",
    "Metadata can automatically be visualized with output viewer(s).\n",
    "Please go [here](https://www.kubeflow.org/docs/pipelines/sdk/output-viewer/) to see how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    data_dir: InputPath(str), model_dir: InputPath(str), metrics_path: OutputPath(str)\n",
    ") -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `/mlpipeline-metrics.json` for Kubeflow Pipelines\n",
    "    metadata.\"\"\"\n",
    "\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "    from collections import namedtuple\n",
    "\n",
    "    def normalize_image(image, label):\n",
    "        return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "    ds_test, ds_info = tfds.load(\n",
    "        \"mnist\",\n",
    "        split=\"test\",\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "        download=False,\n",
    "        data_dir=f\"{data_dir}/datasets\",\n",
    "    )\n",
    "\n",
    "    # See: https://www.tensorflow.org/datasets/keras_example#build_training_pipeline\n",
    "    ds_test = ds_test.map(\n",
    "        normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    ds_test = ds_test.batch(128)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    (loss, accuracy) = model.evaluate(ds_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"loss\", \"numberValue\": str(loss), \"format\": \"PERCENTAGE\"},\n",
    "            {\"name\": \"accuracy\", \"numberValue\": str(accuracy), \"format\": \"PERCENTAGE\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "\n",
    "    return out_tuple(json.dumps(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 4: Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(\n",
    "    model_dir: InputPath(str),\n",
    "    metrics: InputPath(str),\n",
    "    export_bucket: str,\n",
    "    model_name: str,\n",
    "    model_version: int,\n",
    "):\n",
    "    import os\n",
    "    import boto3\n",
    "    from botocore.client import Config\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=\"http://minio.kubeflow-data.svc.cluster.local:9000\",\n",
    "        aws_access_key_id=\"e28283b8c53d412c9b03092e58da51e0\",\n",
    "        aws_secret_access_key=\"d21ade117b8e44508f10e5ae796cf902\",\n",
    "        config=Config(signature_version=\"s3v4\"),\n",
    "    )\n",
    "\n",
    "    # Create export bucket if it does not yet exist\n",
    "    response = s3.list_buckets()\n",
    "    export_bucket_exists = False\n",
    "\n",
    "    for bucket in response[\"Buckets\"]:\n",
    "        if bucket[\"Name\"] == export_bucket:\n",
    "            export_bucket_exists = True\n",
    "\n",
    "    if not export_bucket_exists:\n",
    "        s3.create_bucket(ACL=\"public-read-write\", Bucket=export_bucket)\n",
    "\n",
    "    # Save model files to S3\n",
    "    for root, dirs, files in os.walk(model_dir):\n",
    "        for filename in files:\n",
    "            local_path = os.path.join(root, filename)\n",
    "            s3_path = os.path.relpath(local_path, model_dir)\n",
    "\n",
    "            s3.upload_file(\n",
    "                local_path,\n",
    "                export_bucket,\n",
    "                f\"{model_name}/{model_version}/{s3_path}\",\n",
    "                ExtraArgs={\"ACL\": \"public-read\"},\n",
    "            )\n",
    "\n",
    "    response = s3.list_objects(Bucket=export_bucket)\n",
    "    print(f\"All objects in {export_bucket}:\")\n",
    "    for file in response[\"Contents\"]:\n",
    "        print(\"{}/{}\".format(export_bucket, file[\"Key\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Combine the Components into a Pipeline\n",
    "Note that up to this point we have not yet used the Kubeflow Pipelines SDK!\n",
    "\n",
    "With our four components (i.e. self-contained functions) defined, we can wire up the dependencies with Kubeflow Pipelines.\n",
    "\n",
    "The call [`components.func_to_container_op(f, base_image=img)(*args)`](https://www.kubeflow.org/docs/pipelines/sdk/sdk-overview/) has the following ingredients:\n",
    "- `f` is the Python function that defines a component\n",
    "- `img` is the base (Docker) image used to package the function\n",
    "- `*args` lists the arguments to `f`\n",
    "\n",
    "What the `*args` mean is best explained by going forward through the graph:\n",
    "- `downloadOp` is the very first step and has no dependencies; it therefore has no `InputPath`.\n",
    "  Its output (i.e. `OutputPath`) is stored in `data_dir`.\n",
    "- `trainOp` needs the data downloaded from `downloadOp` and its signature lists `data_dir` (input) and `model_dir` (output).\n",
    "  So, it _depends on_ `downloadOp.output` (i.e. the previous step's output) and stores its own outputs in `model_dir`, which can be used by another step.\n",
    "  `downloadOp` is the parent of `trainOp`, as required.\n",
    "- `evaluateOp`'s function takes three arguments: `data_dir` (i.e. `downloadOp.output`), `model_dir` (i.e. `trainOp.output`), and `metrics_path`, which is where the function stores its evaluation metrics.\n",
    "  That way, `evaluateOp` can only run after the successful completion of both `downloadOp` and `trainOp`.\n",
    "- `exportOp` runs the function `export_model`, which accepts five parameters: `model_dir`, `metrics`, `export_bucket`, `model_name`, and `model_version`.\n",
    "  From where do we get the `model_dir`?\n",
    "  It is nothing but `trainOp.output`.\n",
    "  Similarly, `metrics` is `evaluateOp.output`.\n",
    "  The remaining three arguments are regular Python arguments that are static for the pipeline: they do not depend on any step's output being available.\n",
    "  Hence, they are defined without using `InputPath`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_serve(\n",
    "    data_dir: str,\n",
    "    model_dir: str,\n",
    "    export_bucket: str,\n",
    "    model_name: str,\n",
    "    model_version: int,\n",
    "):\n",
    "    # For GPU support, please add the \"-gpu\" suffix to the base image\n",
    "    BASE_IMAGE = \"mesosphere/kubeflow:1.0.1-0.5.0-tensorflow-2.2.0\"\n",
    "\n",
    "    downloadOp = components.func_to_container_op(\n",
    "        download_dataset, base_image=BASE_IMAGE\n",
    "    )()\n",
    "\n",
    "    trainOp = components.func_to_container_op(train_model, base_image=BASE_IMAGE)(\n",
    "        downloadOp.output\n",
    "    )\n",
    "\n",
    "    evaluateOp = components.func_to_container_op(evaluate_model, base_image=BASE_IMAGE)(\n",
    "        downloadOp.output, trainOp.output\n",
    "    )\n",
    "\n",
    "    exportOp = components.func_to_container_op(export_model, base_image=BASE_IMAGE)(\n",
    "        trainOp.output, evaluateOp.output, export_bucket, model_name, model_version\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case it isn't obvious: this will build the Docker images for you.\n",
    "Each image is based on `BASE_IMAGE` and includes the Python functions as executable files.\n",
    "Each component _can_ use a different base image though.\n",
    "This may come in handy if you want to have reusable components for automatic data and/or model analysis (e.g. to investigate bias).\n",
    "\n",
    "Note that you did not have to use [Kubeflow Fairing](../fairing/Kubeflow%20Fairing.ipynb) or `docker build` locally at all!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Remember when we said all dependencies have to be included in the base image?\n",
    "    Well, that was not quite accurate.\n",
    "    It's a good idea to have everything included and tested before you define and use your pipeline components to make sure that there are not dependency conflicts.\n",
    "    There is, however, a way to add <a href=\"https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.func_to_container_op\">packages (<code>packages_to_install</code>) and additional code to execute <em>before</em> the function code (<code>extra_code</code>)</a>.\n",
    "</div>\n",
    "\n",
    "Is that it?\n",
    "Not quite!\n",
    "\n",
    "We still have to define the pipeline itself.\n",
    "Our `train_and_serve` function defines dependencies but we must use the KFP domain-specific language (DSL) to register the pipeline with its four components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_transformer(op):\n",
    "    op.add_pod_annotation(name=\"sidecar.istio.io/inject\", value=\"false\")\n",
    "    return op\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End-to-End MNIST Pipeline\",\n",
    "    description=\"A sample pipeline to demonstrate multi-step model training, evaluation, export, and serving\",\n",
    ")\n",
    "def mnist_pipeline(\n",
    "    model_dir: str = \"/train/model\",\n",
    "    data_dir: str = \"/train/data\",\n",
    "    export_bucket: str = \"mnist\",\n",
    "    model_name: str = \"mnist\",\n",
    "    model_version: int = 1,\n",
    "):\n",
    "    train_and_serve(\n",
    "        data_dir=data_dir,\n",
    "        model_dir=model_dir,\n",
    "        export_bucket=export_bucket,\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "    )\n",
    "    dsl.get_pipeline_conf().add_op_transformer(op_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in place, let's submit the pipeline directly from our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://kubeflow.needy-falcon-924.bubble.superhub.io/_/pipeline/#/experiments/details/7e4ef7c0-8974-4c49-8e6d-9eb9ebb8365f\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://kubeflow.needy-falcon-924.bubble.superhub.io/_/pipeline/#/runs/details/5534b9d8-8b03-42aa-98bf-26dfb9ac8d24\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_func = mnist_pipeline\n",
    "run_name = pipeline_func.__name__ + \" run\"\n",
    "experiment_name = \"End-to-End MNIST Pipeline\"\n",
    "\n",
    "arguments = {\n",
    "    \"model_dir\": \"/train/model\",\n",
    "    \"data_dir\": \"/train/data\",\n",
    "    \"export_bucket\": \"mnist\",\n",
    "    \"model_name\": \"mnist\",\n",
    "    \"model_version\": \"1\",\n",
    "}\n",
    "\n",
    "client = kfp.Client()\n",
    "#client.set_user_namespace(\"igor\")\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    pipeline_func,\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    arguments=arguments,\n",
    "    namespace=namespace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph will look like this:\n",
    "\n",
    "![Graph](./img/graph.png)\n",
    "\n",
    "If there are any issues with our pipeline definition, this is where they would flare up.\n",
    "So, until you submit it, you won't know if your pipeline definition is correct.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    We have so far claimed that Kubeflow Pipelines is for automation of multi-step (ad hoc) workflows and usage in CI/CD.\n",
    "    You may have wondered why that is.\n",
    "    After all, it is possible to set up <a href=\"https://www.kubeflow.org/docs/pipelines/overview/concepts/run/\">recurring runs</a> of pipelines.\n",
    "    The reason is that these pipeline steps are one-offs.\n",
    "    Even though you can parameterize each step, including the ones that kick off an entire pipeline, there is no orchestration of workflows.\n",
    "    Stated differently, if a step fails, there is no mechanism for automatic retries.\n",
    "    Nor is there any support for marking success: if the step is scheduled to be run again, it will be run again, whether or not the previous execution was successful, obviating any subsequent runs (except in cases where it may be warranted).\n",
    "    Kubeflow Pipelines allows <a href=\"https://www.kubeflow.org/docs/pipelines/reference/api/kubeflow-pipeline-api-spec/#operation--apis-v1beta1-runs--run_id--retry-post\">retries</a> but it is not configurable out of the box.\n",
    "    If you want Airflow- or Luigi-like behaviour for dependency management of workflows, Kubeflow Pipelines is not the tool.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve the model with Seldon\n",
    "\n",
    "* Deploy the model using Seldon\n",
    "* We need to create\n",
    "  1. A Kubernetes Deployment\n",
    "  2. A Kubernetes service\n",
    "  3. (Optional) Create a configmap containing the prometheus monitoring config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k8s_util\n",
    "# Force a reload of kubeflow; since kubeflow is a multi namespace module\n",
    "# it looks like doing this in notebook_setup may not be sufficient\n",
    "from kubernetes import client as k8s_client\n",
    "from kubernetes import config as k8s_config\n",
    "from kubeflow.tfjob.api import tf_job_client as tf_job_client_module\n",
    "from IPython.core.display import display, HTML\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace=\"seldon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_spec = f\"\"\"apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "metadata:\n",
    "  name: seldon-init-container-secret\n",
    "  namespace: {namespace}\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: admin\n",
    "  AWS_SECRET_ACCESS_KEY: Admin123\n",
    "  AWS_ENDPOINT_URL: https://buckets.app.small-julie-379.bubble.superhub.io/\n",
    "  USE_SSL: \"true\"\n",
    "\"\"\"\n",
    "\n",
    "minio_specs = [secret_spec]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add admin permissions to the notebook user using the following command: <br>`kubectl create clusterrolebinding workspace-cluster-admin --clusterrole=cluster-admin --serviceaccount=workspace:default-editor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201229 05:52:06 k8s_util:114] Deleted Secret seldon.seldon-init-container-secret\n",
      "[I 201229 05:52:06 k8s_util:118] Created Secret seldon.seldon-init-container-secret\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'api_version': 'v1',\n",
       "  'data': {'AWS_ACCESS_KEY_ID': 'YWRtaW4=',\n",
       "           'AWS_ENDPOINT_URL': 'aHR0cHM6Ly9idWNrZXRzLmFwcC5zbWFsbC1qdWxpZS0zNzkuYnViYmxlLnN1cGVyaHViLmlvLw==',\n",
       "           'AWS_SECRET_ACCESS_KEY': 'QWRtaW4xMjM=',\n",
       "           'USE_SSL': 'dHJ1ZQ=='},\n",
       "  'kind': 'Secret',\n",
       "  'metadata': {'annotations': None,\n",
       "               'cluster_name': None,\n",
       "               'creation_timestamp': datetime.datetime(2020, 12, 29, 5, 52, 6, tzinfo=tzlocal()),\n",
       "               'deletion_grace_period_seconds': None,\n",
       "               'deletion_timestamp': None,\n",
       "               'finalizers': None,\n",
       "               'generate_name': None,\n",
       "               'generation': None,\n",
       "               'initializers': None,\n",
       "               'labels': None,\n",
       "               'managed_fields': None,\n",
       "               'name': 'seldon-init-container-secret',\n",
       "               'namespace': 'seldon',\n",
       "               'owner_references': None,\n",
       "               'resource_version': '7865882',\n",
       "               'self_link': '/api/v1/namespaces/seldon/secrets/seldon-init-container-secret',\n",
       "               'uid': '889ee41e-4bc1-4720-8c2b-4beaf785aeab'},\n",
       "  'string_data': None,\n",
       "  'type': 'Opaque'}]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k8s_util.apply_k8s_specs(minio_specs, k8s_util.K8S_CREATE_OR_REPLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path=\"s3://mnist/mnist\"\n",
    "#export_path=\"s3://small-sa-mnist/mnist/export\"\n",
    "#export_path=\"gs://seldon-models/tfserving/mnist-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_name = \"tfserving\"\n",
    "model_base_path = export_path\n",
    "\n",
    "# The web ui defaults to mnist2-service so if you change it you will\n",
    "# need to change it in the UI as well to send predictions to the mode\n",
    "model_service = \"mnist2-service\"\n",
    "\n",
    "deploy_spec = f\"\"\"apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: {deploy_name}\n",
    "  namespace: {namespace}\n",
    "  annotations:        \n",
    "    sidecar.istio.io/inject: \"false\"\n",
    "spec:\n",
    "  name: mnist\n",
    "  serviceAccount: default-editor\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: TENSORFLOW_SERVER\n",
    "      modelUri: {model_base_path}\n",
    "      envSecretRefName: seldon-init-container-secret\n",
    "      name: mnist\n",
    "      parameters:\n",
    "        - name: signature_name\n",
    "          type: STRING\n",
    "          value: serving_default\n",
    "        - name: model_name\n",
    "          type: STRING\n",
    "          value: mnist\n",
    "        - name: model_input\n",
    "          type: STRING\n",
    "          value: images\n",
    "        - name: model_output\n",
    "          type: STRING\n",
    "          value: scores     \n",
    "    name: default\n",
    "    replicas: 1\n",
    "\"\"\"\n",
    "\n",
    "service_spec = f\"\"\"apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  annotations:    \n",
    "    prometheus.io/path: /monitoring/prometheus/metrics\n",
    "    prometheus.io/port: \"8500\"\n",
    "    prometheus.io/scrape: \"true\"\n",
    "  labels:\n",
    "    app: mnist-model\n",
    "  name: {model_service}\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  ports:\n",
    "  - name: grpc-tf-serving\n",
    "    port: 9000\n",
    "    targetPort: 9000\n",
    "  - name: http-tf-serving\n",
    "    port: 8500\n",
    "    targetPort: 8500\n",
    "  selector:\n",
    "    app: mnist-model\n",
    "  type: ClusterIP\n",
    "\"\"\"\n",
    "\n",
    "monitoring_config = f\"\"\"kind: ConfigMap\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: {deploy_name}\n",
    "  namespace: {namespace}\n",
    "data:\n",
    "  monitoring_config.txt: |-\n",
    "    prometheus_config: {{\n",
    "      enable: true,\n",
    "      path: \"/monitoring/prometheus/metrics\"\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "model_specs = [deploy_spec, service_spec, monitoring_config]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201229 05:56:27 k8s_util:114] Deleted SeldonDeployment seldon.tfserving\n",
      "[I 201229 05:56:27 k8s_util:118] Created SeldonDeployment tfserving.tfserving\n",
      "[I 201229 05:56:27 k8s_util:114] Deleted Service seldon.mnist2-service\n",
      "[I 201229 05:56:27 k8s_util:118] Created Service seldon.mnist2-service\n",
      "[I 201229 05:56:27 k8s_util:114] Deleted ConfigMap seldon.tfserving\n",
      "[I 201229 05:56:27 k8s_util:118] Created ConfigMap seldon.tfserving\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'apiVersion': 'machinelearning.seldon.io/v1alpha2',\n",
       "  'kind': 'SeldonDeployment',\n",
       "  'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'},\n",
       "   'creationTimestamp': '2020-12-29T05:56:27Z',\n",
       "   'generation': 1,\n",
       "   'name': 'tfserving',\n",
       "   'namespace': 'seldon',\n",
       "   'resourceVersion': '7867018',\n",
       "   'selfLink': '/apis/machinelearning.seldon.io/v1alpha2/namespaces/seldon/seldondeployments/tfserving',\n",
       "   'uid': 'f7e2d7d5-0c09-462d-85f5-3b919cbaaf38'},\n",
       "  'spec': {'name': 'mnist',\n",
       "   'predictors': [{'graph': {'children': [],\n",
       "      'envSecretRefName': 'seldon-init-container-secret',\n",
       "      'implementation': 'TENSORFLOW_SERVER',\n",
       "      'modelUri': 's3://mnist/mnist',\n",
       "      'name': 'mnist',\n",
       "      'parameters': [{'name': 'signature_name',\n",
       "        'type': 'STRING',\n",
       "        'value': 'serving_default'},\n",
       "       {'name': 'model_name', 'type': 'STRING', 'value': 'mnist'},\n",
       "       {'name': 'model_input', 'type': 'STRING', 'value': 'images'},\n",
       "       {'name': 'model_output', 'type': 'STRING', 'value': 'scores'}]},\n",
       "     'name': 'default',\n",
       "     'replicas': 1}],\n",
       "   'serviceAccount': 'default-editor'}},\n",
       " {'api_version': 'v1',\n",
       "  'kind': 'Service',\n",
       "  'metadata': {'annotations': {'prometheus.io/path': '/monitoring/prometheus/metrics',\n",
       "                               'prometheus.io/port': '8500',\n",
       "                               'prometheus.io/scrape': 'true'},\n",
       "               'cluster_name': None,\n",
       "               'creation_timestamp': datetime.datetime(2020, 12, 29, 5, 56, 27, tzinfo=tzlocal()),\n",
       "               'deletion_grace_period_seconds': None,\n",
       "               'deletion_timestamp': None,\n",
       "               'finalizers': None,\n",
       "               'generate_name': None,\n",
       "               'generation': None,\n",
       "               'initializers': None,\n",
       "               'labels': {'app': 'mnist-model'},\n",
       "               'managed_fields': None,\n",
       "               'name': 'mnist2-service',\n",
       "               'namespace': 'seldon',\n",
       "               'owner_references': None,\n",
       "               'resource_version': '7867053',\n",
       "               'self_link': '/api/v1/namespaces/seldon/services/mnist2-service',\n",
       "               'uid': 'a868e5bd-192f-41e4-a552-33071b5af57f'},\n",
       "  'spec': {'cluster_ip': '10.100.147.195',\n",
       "           'external_i_ps': None,\n",
       "           'external_name': None,\n",
       "           'external_traffic_policy': None,\n",
       "           'health_check_node_port': None,\n",
       "           'load_balancer_ip': None,\n",
       "           'load_balancer_source_ranges': None,\n",
       "           'ports': [{'name': 'grpc-tf-serving',\n",
       "                      'node_port': None,\n",
       "                      'port': 9000,\n",
       "                      'protocol': 'TCP',\n",
       "                      'target_port': 9000},\n",
       "                     {'name': 'http-tf-serving',\n",
       "                      'node_port': None,\n",
       "                      'port': 8500,\n",
       "                      'protocol': 'TCP',\n",
       "                      'target_port': 8500}],\n",
       "           'publish_not_ready_addresses': None,\n",
       "           'selector': {'app': 'mnist-model'},\n",
       "           'session_affinity': 'None',\n",
       "           'session_affinity_config': None,\n",
       "           'type': 'ClusterIP'},\n",
       "  'status': {'load_balancer': {'ingress': None}}},\n",
       " {'api_version': 'v1',\n",
       "  'binary_data': None,\n",
       "  'data': {'monitoring_config.txt': 'prometheus_config: {\\n'\n",
       "                                    '  enable: true,\\n'\n",
       "                                    '  path: \"/monitoring/prometheus/metrics\"\\n'\n",
       "                                    '}'},\n",
       "  'kind': 'ConfigMap',\n",
       "  'metadata': {'annotations': None,\n",
       "               'cluster_name': None,\n",
       "               'creation_timestamp': datetime.datetime(2020, 12, 29, 5, 56, 27, tzinfo=tzlocal()),\n",
       "               'deletion_grace_period_seconds': None,\n",
       "               'deletion_timestamp': None,\n",
       "               'finalizers': None,\n",
       "               'generate_name': None,\n",
       "               'generation': None,\n",
       "               'initializers': None,\n",
       "               'labels': None,\n",
       "               'managed_fields': None,\n",
       "               'name': 'tfserving',\n",
       "               'namespace': 'seldon',\n",
       "               'owner_references': None,\n",
       "               'resource_version': '7867060',\n",
       "               'self_link': '/api/v1/namespaces/seldon/configmaps/tfserving',\n",
       "               'uid': 'b3276013-9a6f-4786-9450-38906cafaf45'}}]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k8s_util.apply_k8s_specs(model_specs, k8s_util.K8S_CREATE_OR_REPLACE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_image(x_test, image_index):\n",
    "    plt.imshow(x_test[image_index].reshape(28, 28), cmap=\"binary\")\n",
    "\n",
    "\n",
    "def predict_number(model, x_test, image_index):\n",
    "    pred = model.predict(x_test[image_index : image_index + 1])\n",
    "    print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with np.load(\"datasets/mnist.npz\", allow_pickle=True) as f:\n",
    "    x_test = (\n",
    "        f[\"x_test\"] / 255.0\n",
    "    )  # We must transform the data in the same way as before!\n",
    "\n",
    "image_index = 101\n",
    "\n",
    "display_image(x_test, image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = x_test[image_index : image_index + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities for each class (0-9) are shown in the `predictions` response.\n",
    "The model believes the image shows a \"0\", which indeed it does!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN=\"MTYwOTE5MDExNXxOd3dBTkVnMlRFdGFOMU0zU1ZCSVZGZzBSVmRSUkZwUVYxcEhXVkZNVGxCVFQwWllSRFJOVFZkVVVsVlRUa3BOVFZaTlZEWlhTRUU9fD5h8q0EUw7adNfzGn_F-fpsffnT6wMOoeZ6XdUz2VmM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient, SeldonChannelCredentials, SeldonCallCredentials\n",
    "host = \"kubeflow.small-julie-379.bubble.superhub.io\"\n",
    "port = \"443\" # Make sure you use the port above\n",
    "ISTIO_GATEWAY=host + \":\" + port\n",
    "deployment_name = \"tfserving\"\n",
    "transport=\"rest\"\n",
    "namespace=\"seldon\"\n",
    "\n",
    "sc = SeldonClient(deployment_name=deployment_name,namespace=namespace,gateway_endpoint=ISTIO_GATEWAY,debug=False,\n",
    "                 channel_credentials=SeldonChannelCredentials(verify=False),\n",
    "                 call_credentials=SeldonCallCredentials(token=TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:True message:\n",
      "Request:\n",
      "meta {\n",
      "}\n",
      "data {\n",
      "  tensor {\n",
      "    shape: 1\n",
      "    shape: 28\n",
      "    shape: 28\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.14901960784313725\n",
      "    values: 0.7647058823529411\n",
      "    values: 0.8941176470588236\n",
      "    values: 0.25098039215686274\n",
      "    values: 0.3215686274509804\n",
      "    values: 0.611764705882353\n",
      "    values: 0.08235294117647059\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.1607843137254902\n",
      "    values: 0.8784313725490196\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.996078431372549\n",
      "    values: 0.9764705882352941\n",
      "    values: 0.8313725490196079\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.8156862745098039\n",
      "    values: 0.0784313725490196\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.5372549019607843\n",
      "    values: 0.796078431372549\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.8901960784313725\n",
      "    values: 0.8156862745098039\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.4392156862745098\n",
      "    values: 0.8352941176470589\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.803921568627451\n",
      "    values: 0.03529411764705882\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.5294117647058824\n",
      "    values: 0.9764705882352941\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.6549019607843137\n",
      "    values: 0.1607843137254902\n",
      "    values: 0.592156862745098\n",
      "    values: 0.7137254901960784\n",
      "    values: 0.08235294117647059\n",
      "    values: 0.403921568627451\n",
      "    values: 0.9647058823529412\n",
      "    values: 0.996078431372549\n",
      "    values: 0.24705882352941178\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.3843137254901961\n",
      "    values: 0.996078431372549\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.8117647058823529\n",
      "    values: 0.13725490196078433\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.023529411764705882\n",
      "    values: 0.30980392156862746\n",
      "    values: 0.7411764705882353\n",
      "    values: 0.9294117647058824\n",
      "    values: 0.22745098039215686\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.17647058823529413\n",
      "    values: 0.996078431372549\n",
      "    values: 1.0\n",
      "    values: 0.996078431372549\n",
      "    values: 0.1411764705882353\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.41568627450980394\n",
      "    values: 0.996078431372549\n",
      "    values: 0.7254901960784313\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.08235294117647059\n",
      "    values: 0.8784313725490196\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.996078431372549\n",
      "    values: 0.5098039215686274\n",
      "    values: 0.011764705882352941\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0196078431372549\n",
      "    values: 0.596078431372549\n",
      "    values: 0.8784313725490196\n",
      "    values: 0.047058823529411764\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.1450980392156863\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.6235294117647059\n",
      "    values: 0.03529411764705882\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.26666666666666666\n",
      "    values: 0.9686274509803922\n",
      "    values: 0.1803921568627451\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.2980392156862745\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.23921568627450981\n",
      "    values: 0.9098039215686274\n",
      "    values: 0.09411764705882353\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.6235294117647059\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.44313725490196076\n",
      "    values: 0.9411764705882353\n",
      "    values: 0.13725490196078433\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.7294117647058823\n",
      "    values: 0.996078431372549\n",
      "    values: 0.8941176470588236\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.21568627450980393\n",
      "    values: 0.9529411764705882\n",
      "    values: 0.15294117647058825\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.2\n",
      "    values: 0.9803921568627451\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.3058823529411765\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.16470588235294117\n",
      "    values: 0.9137254901960784\n",
      "    values: 0.8470588235294118\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.21568627450980393\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.2823529411764706\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.4666666666666667\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.6705882352941176\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.12549019607843137\n",
      "    values: 0.9058823529411765\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.3333333333333333\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.1568627450980392\n",
      "    values: 0.9176470588235294\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.21568627450980393\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.24313725490196078\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.1568627450980392\n",
      "    values: 0.7098039215686275\n",
      "    values: 0.996078431372549\n",
      "    values: 0.7098039215686275\n",
      "    values: 0.043137254901960784\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.10588235294117647\n",
      "    values: 0.8313725490196079\n",
      "    values: 0.996078431372549\n",
      "    values: 0.6666666666666666\n",
      "    values: 0.0196078431372549\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.6549019607843137\n",
      "    values: 0.996078431372549\n",
      "    values: 0.9176470588235294\n",
      "    values: 0.050980392156862744\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.42745098039215684\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.996078431372549\n",
      "    values: 0.396078431372549\n",
      "    values: 0.03137254901960784\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.2\n",
      "    values: 0.6196078431372549\n",
      "    values: 0.9764705882352941\n",
      "    values: 0.9137254901960784\n",
      "    values: 0.43137254901960786\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.08627450980392157\n",
      "    values: 0.5450980392156862\n",
      "    values: 0.996078431372549\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.8705882352941177\n",
      "    values: 0.6980392156862745\n",
      "    values: 0.5019607843137255\n",
      "    values: 0.8549019607843137\n",
      "    values: 0.9333333333333333\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9058823529411765\n",
      "    values: 0.19215686274509805\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0784313725490196\n",
      "    values: 0.5647058823529412\n",
      "    values: 0.8941176470588236\n",
      "    values: 0.9803921568627451\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.9921568627450981\n",
      "    values: 0.996078431372549\n",
      "    values: 0.9764705882352941\n",
      "    values: 0.7411764705882353\n",
      "    values: 0.3254901960784314\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.24313725490196078\n",
      "    values: 0.2823529411764706\n",
      "    values: 0.6627450980392157\n",
      "    values: 0.4117647058823529\n",
      "    values: 0.2235294117647059\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "    values: 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "Response:\n",
      "{'data': {'names': ['t:0', 't:1', 't:2', 't:3', 't:4', 't:5', 't:6', 't:7', 't:8', 't:9'], 'tensor': {'shape': [1, 10], 'values': [0.999834538, 3.01934335e-07, 3.16104592e-06, 2.71896312e-07, 2.33503528e-07, 1.41523096e-05, 2.49492296e-05, 0.000119655379, 2.53527077e-07, 2.52412633e-06]}}, 'meta': {}}\n"
     ]
    }
   ],
   "source": [
    "r = sc.predict(gateway=\"istio\",transport=\"rest\",data=darray)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities for each class (0-9) are shown in the `predictions` response.\n",
    "The model believes the image shows a \"0\", which indeed it does!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'names': ['t:0', 't:1', 't:2', 't:3', 't:4', 't:5', 't:6', 't:7', 't:8', 't:9'], 'tensor': {'shape': [1, 10], 'values': [0.999834538, 3.01934335e-07, 3.16104592e-06, 2.71896312e-07, 2.33503528e-07, 1.41523096e-05, 2.49492296e-05, 0.000119655379, 2.53527077e-07, 2.52412633e-06]}}, 'meta': {}}\n"
     ]
    }
   ],
   "source": [
    "print (r.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have completed the tutorial!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
